# Autism Genetics and Brain Connectivity Analysis

## Project Goals
This repository collects the code used to test how brain connectivity patterns may relate to differences in genetic predisposition to autism and to social difficulties. The workflow links Human Connectome Project (HCP) behavioural measures, polygenic scores (PGS) derived from external autism GWAS, and resting-state fMRI connectomes. The analyses proceed in three blocks:

- build a latent social-difficulty factor from HCP behavioural tasks and questionnaires;
- translate external GWAS results into subject-level polygenic scores for the HCP cohort;
- relate genetic scores to macroscale brain network organisation with both univariate and multivariate approaches.

## Repository Layout
- `code/`: analysis scripts grouped by stage (A = behavioural, B = genetics, C = brain) plus helper modules.
- `data/`: anonymised inputs, processed tables, intermediate products, and PLINK working directory (not versioned for regulated datasets).
- `figures/`: plots generated by the scripts (behavioural QC, PRS diagnostics, network visualisations).
- `results/`: placeholder for statistical output ready for manuscripts.
- `.devcontainer/`: Docker + VS Code configuration and bootstrap script for the conda environment and external tools.

## Data Inputs
All raw inputs are stored under `data/` and are not publicly distributed. You will need local access to:

- HCP behavioural (`behavioural_data_anonymised.csv`), phenotypic (`phenotypic_data_anonymised.csv`), motion (`movement_data_anonymised.csv`), and subject ID files (`subjectIDs_anonymised.txt`).
- Resting-state functional connectivity matrices from the HCP PTN 1200 release (`data/HCP_PTN1200/netmats/...`).
- NeuroChip genotype data for the HCP sample (`data/genetics_data/Neuro_Chip*`).
- Autism spectrum disorder GWAS summary statistics (`data/genetics_data/iPSYCH_PGC_ASD_Nov_2017.gz`).

## Computational Environment
- The conda specification (`environment.yml`) installs the Python and R packages needed for all analyses. `requirements.txt` pins a few pip-only neuroimaging utilities.
- `.devcontainer/setup.sh` automates environment creation and downloads command-line genetics tools (PRSice, PLINK 1.9, GCTA 1.94). Update the download URLs if newer binaries are preferred.
- Large parts of the pipeline rely on these external binaries being on your `PATH`. The setup script appends them to `~/.bashrc` inside the container; mirror that behaviour if running locally.

## Analysis Pipeline
The scripts are designed to run sequentially, though you can enter at any stage if the required inputs already exist. File outputs are saved inside `data/`, `figures/`, or `results/` unless noted otherwise.

### A. Behavioural Factor Construction
1. `python code/A1_preprocess_phenotypic_data.py`
   - Cleans and merges behavioural + phenotypic HCP files, removes participants with globally missing data (no fMRI or genetics), winsorises response-time outliers, imputes missing values with MICE, and exports `behavioural_data_preprocessed.csv` and QC figures/tables.
2. `Rscript code/A2_factor_analysis.R`
   - Runs exploratory factor analyses to compare candidate latent structures, then fits a single-factor CFA for social difficulties. Outputs include model fit summaries (`efa_model_comparison.csv`, `cfa_fit_indices.csv`), normalised factor scores for every subject (`cfa_factor_scores_full_sample.csv`), and a GCTA-ready phenotype file (`cfa_factor_scores.txt`).
3. `python code/A3_evaluate_social_factor.py`
   - Benchmark step: correlates the factor scores with HCP cognitive composites.

### B. Polygenic Risk Modelling
1. `bash code/B1_translate_PRS_to_HCP.sh`
   - Performs PLINK-based quality control, allele harmonisation against the GWAS (via `code/snp_mismatched.R`), sex and relatedness filtering, eigenvector calculation, and a first PRSice run for unrelated individuals. Intermediate PLINK binaries are written to `data/plink/`.
2. `python code/B2_select_PRS_threshold.py`
   - Merges unrelated-sample PRS scores with CFA factor scores and population PCs to select p-value thresholds, regresses out ancestry effects, and saves the best-performing scores as `unrelated_PGS_scores_pc_corrected.txt` alongside a threshold comparison table.
3. `bash code/B3_extend_PRS_with_BLUP.sh`
   - Uses GCTA to build a genomic relationship matrix, fits a linear mixed model on the unrelated sample, obtains SNP-wise BLUP weights, and projects them back to the whole cohort, yielding `full_prs_scores.snp.blp.profile` and PCA covariates for the full sample.
4. `python code/B4_evalute_BLUP_prediction.py`
   - Evaluates the correspondence between original and BLUP-extended scores, fits covariate-adjusted regressions on the social factor, derives residualised PGS (`prs_residuals.csv`), and produces comparison figures.

### C. Brain Connectivity Analyses
1. `python code/C1_run_univariate_fMRI_prediction.py`
   - Residualises edge weights for demographic and motion covariates, relates each connectivity edge to social scores, applies FDR correction, and contrasts low / middle / high PGS groups.
2. `python code/C2_run_multivariate_fMRI_prediction.py`
   - Fits PLS regression models to predict social scores from whole-brain connectivity, including cross-validation, bootstrap confidence intervals, and group-wise performance comparisons.
3. `python code/C3_find_communities_fMRI.py`
   - Generates consensus community partitions by testing Louvain resolution parameters, evaluates modularity and stability, and saves atlas partitions for downstream use.
4. `python code/C4_perform_main_landscape_analysis.py`
   - Computes modularity and global efficiency for each participant, relates them to social scores overall and within PGS strata, and tests variability/compensation predictions from landscape theory.
5. `python code/C5_perform_sensitivity_landscape_analysis.py`
   - Repeats the landscape analyses across multiple parcellations (50/100/200 nodes) and density thresholds to assess robustness.
   - Bootstraps group-average connectivity matrices, reorders them by detected communities, and saves publication-ready heatmaps for each PGS group.

### Helper Modules
- `code/connectome_viz.py`: utility functions for mapping vectorised connectivity indices back to matrices and for custom connectome visualisations.
- `code/snp_mismatched.R`: allele matching logic invoked inside the PRS translation pipeline.

## Running the Workflow
1. Clone the repository and ensure the required raw data live in `data/` with the expected filenames.
2. Build the environment: either open the project in VS Code Dev Containers or run `conda env create -f environment.yml` followed by `pip install -r requirements.txt` manually. Install PRSice, PLINK, and GCTA (see `.devcontainer/setup.sh`). Please note that the setup code is intended for Linux operating systems; MacOS users may need to adjust the download URLs and binary names.
3. Activate the environment (`conda activate BrainComp`) and add the external binaries to your `PATH`.
4. Run the scripts from section **Analysis Pipeline** in order. Steps B1–B3 are computationally intensive and may require substantial RAM/disk and several hours. The connectome analyses (C1–C6) expect ~20 GB free memory and benefit from parallel execution if available.
5. Inspect outputs in `data/`, `figures/`, and `results/`. Most statistical tables are exported as CSV for further inspection.

## Outputs
- Behavioural QC: `data/descriptive_statistics_table.csv`, `figures/*outliers.png`, `figures/Behaviour_correlations.png`.
- Factor models: `data/efa_model_comparison.csv`, `data/cfa_fit_indices.csv`, `data/cfa_factor_scores_full_sample.csv`.
- Genetics: PLINK binaries under `data/plink/`, `data/prs_residuals.csv`, `figures/PGS_*`.
- Brain analyses: connectivity partitions in `data/final_partition_*`, bootstrap averages (`data/avg_connectivity_*`), and network visualisations in `figures/`.

## Reproducibility Notes
- The anonymised HCP phenotypic, behavioural, motion, and genetic datasets are subject to data use agreements and are not distributed with the repository.
- PRSice, PLINK, and GCTA binaries have platform-specific requirements. Confirm the downloaded versions match your operating system.
- All scripts assume they are run from the repository root so relative paths resolve correctly; use `python code/<script>.py` (or the equivalent R/bash command) from the project root.
- The surface plotting functions do not work in headless environments, because they rely on 3D rendering librariers. Therefore, the relevant sections are commented out. If you want to generate surface plots, please run the scripts in an environment that supports graphical output and uncomment the relevant lines.

## Contact
Questions or suggestions can be raised via issues in the repository or by contacting Dr Joe Bathelt (j.m.c.bathelt [at] uva.nl).
